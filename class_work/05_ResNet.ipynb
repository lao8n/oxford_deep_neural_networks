{"cells":[{"cell_type":"markdown","metadata":{"id":"133m8ys9nzHj"},"source":["In the previous practical we worked on a relatively small CNN-based model and observe how different approaches to regularize such model contributed to reach higher accuracies and less overfitting.\n","\n","In this practical we'll use those techinques but start by defining a more advance model based on the [ResNet](https://arxiv.org/pdf/1512.03385.pdf) architecture."]},{"cell_type":"code","source":["!git clone https://github.com/mackopes/DNN_Practicals_Extras.git extras"],"metadata":{"id":"eKhuTAGpRkM_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bVM0Ee_aB23z"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import time\n","import os\n","from tensorboard import notebook\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","%matplotlib inline\n","\n","from IPython.display import Image\n","\n","import extras.p05_p09.miscFuncs as misc"]},{"cell_type":"markdown","metadata":{"id":"DuvNn8GVoPho"},"source":["# A Residual Architecture\n","\n","We have seen several popular architectures that the research community designed and pushed the capabilities of image classification networks forward. Today, residual layer connections, introduced with [ResNet](https://arxiv.org/pdf/1512.03385.pdf), have become a standard when training deep networks. Residual connections help during backpropagation addressing the gradient vanishing problem. Originally proposed in 2014, residual layers are still used in many of state of the art architectures in image classification and beyond.\n","\n","Below, see a set of diagrams that illustrate the design of a standard residual layer (a), a bottleneck layer (b), both originally proposed when ResNet was introduced. Short after, [SqueezeNet](https://arxiv.org/pdf/1602.07360.pdf) proposed the Fire Module (c) which could be seen as a variant of residual layer when concatenating input and output. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujlHofQPrUcB"},"outputs":[],"source":["Image(filename='./extras/p05_p09/layers.png') "]},{"cell_type":"markdown","metadata":{"id":"fiV7rliutmqZ"},"source":["## Residual Layers in Pytorch\n","\n","Implementing each of the layers above (which are comprised of several [torch.nn.conv2d]() layers) should be straightforward. Below, we show how a standard residual layer can be implemented."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xfN6RFFdBHGD"},"outputs":[],"source":["class basicResidualLayer(nn.Module):\n","    def __init__(self, inChannels, outChannels, kernelSize, stride=1):\n","        super(basicResidualLayer, self).__init__()\n","        self.inLayer = nn.Sequential(\n","                    nn.Conv2d(inChannels, outChannels, kernelSize, stride=1, padding=1, bias=False),\n","                    nn.BatchNorm2d(outChannels),\n","                    nn.ReLU()\n","                    )\n","        \n","        self.outLayer = nn.Sequential(\n","                    nn.Conv2d(outChannels, outChannels, kernelSize, stride=1, padding=1, bias=False),\n","                    nn.BatchNorm2d(outChannels)\n","                    )\n","        \n","        # if inchannels = outChannels, then the input can be directly added to the output of the second convolutional layer\n","        # if the above condition isn't true, then we need to expand the input in the channel dimension so the `add` can be done\n","        # A similar strategy would be needed if the widthxheight of the output of the second convolutional layer is smaller than\n","        # that of the input. In this case, however, we'll have to introduce a stride value to the 1x1 conv layer to fix the shape mismatch\n","        self.residualConnection = None\n","        \n","        if inChannels != outChannels:\n","          self.residualConnection = nn.Sequential(\n","                                    nn.Conv2d(inChannels, outChannels, kernel_size=1, stride=1, bias = False),\n","                                    nn.BatchNorm2d(outChannels))\n","        \n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        \n","        residual = x\n","        out = self.inLayer(x) \n","        # print(out.shape)\n","\n","        out = self.outLayer(out)\n","        # print(out.shape)\n","        # here we are adding the input to the output tensor\n","        if self.residualConnection is not None:\n","          residual = self.residualConnection(residual)\n","\n","        out += residual\n","        # print(out.shape)\n","      \n","        # finally, pass the output through the activation\n","        return self.relu(out)"]},{"cell_type":"markdown","metadata":{"id":"9O30MK3iB6SO"},"source":["Now we can evaluate this single layer with randomly initialized tensor in order to verify that the layer has been properly defined."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fW1ZB4VKCDzF"},"outputs":[],"source":["numImages = 128\n","width = height = 9\n","inCh = 32\n","outCh = 64\n","\n","myResidual = basicResidualLayer(inCh, outCh, 3)\n","\n","dummy_input = torch.randn(numImages, inCh, width, height)\n","\n","# pass the input (this will call the forward() method of your module)\n","output = myResidual(dummy_input)\n","\n","# the expected output is [numImages, outCh, width, height]\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"Brv9wvbnHFEH"},"source":["**(optional) Exercise**: Implement a Bottleneck Layer. Follow the design of the `basicResidualLayer` module above and keep the `inChannels` and `outChannels` as the only parameters to initialize the layer. Then, verify you've constructed if correctly by passing a randomly initialized tensor."]},{"cell_type":"markdown","metadata":{"id":"4X0zH9C0IaFP"},"source":["**Complete your code here:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GytDjWh3IkZU"},"outputs":[],"source":["# Your Bottleneck Layer code\n","class bottleneckLayer(nn.Module):\n","    def __init__(self, inChannels, midChannels):\n","        super(bottleneckLayer, self).__init__()\n","        # complete your code here\n","        self.inLayer = nn.Sequential(\n","                    nn.Conv2d(inChannels, midChannels, 1, stride=1, padding=1, bias=False),\n","                    nn.BatchNorm2d(outChannels),\n","                    nn.ReLU()\n","        )\n","        \n","        self.midLayer = nn.Sequential(\n","                    nn.Conv2d(midChannels, midChannels, kernelSize, stride=1, padding=1, bias=False),\n","                    nn.BatchNorm2d(midChannels),\n","                    nn.ReLU()\n","        )\n","        \n","        self.outLayer = nn.Sequential(\n","                    nn.Conv2d(midChannels, inChannels, 1, stride=1, padding=1, bias=False),\n","                    nn.BatchNorm2d(midChannels),\n","                    nn.ReLU(),\n","        )\n","\n","        self.residualConnection = None\n","        \n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        # complete your code here\n","        residual = x\n","        x = self.inLayer(x) \n","\n","        x = self.midLayer(x)\n","\n","        x = self.outLayer(x)\n","\n","        x += residual\n","        # print(out.shape)\n","      \n","        # finally, pass the output through the activation\n","        return self.relu(x)"]},{"cell_type":"markdown","metadata":{"id":"SatmxeaLIeyW"},"source":["And **verify your implementantion here**:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIyN_l4pIoth"},"outputs":[],"source":["# Verify your Bottleneck Layer implementation is correct\n","numImages = 128\n","width = height = 9\n","inCh = 128\n","outCh = 64\n","\n","myBottleNeck = bottleneckLayer(inCh, outCh)\n","\n","dummy_input = torch.randn(numImages, inCh, width, height)\n","\n","# pass the input (this will call the forward() method of your module)\n","output = myBottleNeck(dummy_input)\n","\n","# the expected output is [numImages, outCh, width, height]\n","print(output.shape)"]},{"cell_type":"markdown","metadata":{"id":"yB1b-8aCtrMd"},"source":["## The ResNet-9 Architecture"]},{"cell_type":"markdown","metadata":{"id":"0LK29k3HM2a1"},"source":["So far, we have trained CNNs for image classification on the CIFAR-10 dataset using relativelly simple models. To push the accuracy even higher we need to either build a significantly larger model with more layers and parameters or use a more exotic architectural design. For this part of the practical (and in some future ones) we'll be using an architecture inspired by ResNets. \n","\n","In order to keep the training times to the minimum, we chose an optimized implementation of ResNet9. This architecture can reach **94% in just 24 epochs of training taking a total of 26 seconds** using a single GPU. To achieve this, this architecture makes use of several optimization techniques that are beyond the scope of this course. These include:\n","\n","*   Using larger mini-batches with 512 images.\n","*   Used `cutout` data augmentation.\n","*   Custom piecewise `lr` scheduling.\n","*   Using half-precision arithmetic.\n","\n","(optional) For a complete description on how and why these optimizations were implemented, please refer to this [blog post](https://myrtle.ai/how-to-train-your-resnet/).\n","\n","For the topics we'll be covering in this and the next practical, we have slightly updated the code originally provided in [the GitHub repo](https://github.com/davidcpage/cifar10-fast).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EgpofakqrpLX"},"outputs":[],"source":["from extras.p05_p09.core import *\n","from extras.p05_p09.torch_backend import *\n","import extras.p05_p09.ResNet9Funcs as ResNet9\n","import extras.p05_p09.miscFuncs as misc\n","import extras.p05_p09.utilsFuncs as utils"]},{"cell_type":"markdown","metadata":{"id":"GVL9Xrn3CwBo"},"source":["Let's visualize the architecture of our ResNet9 network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3ydX8S0_F9l"},"outputs":[],"source":["Image(filename='./extras/p05_p09/ResNet9Arch.png') "]},{"cell_type":"markdown","metadata":{"id":"KNzpz0xaC7W4"},"source":["Below, we define the `main()` function. It follows a similar structure as in the previous practicals even though we had to accomodate some parts to the structure of the ResNet9 repository we're building upon."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xzb-sIiCr3gE"},"outputs":[],"source":["def main(epochs, batch_size, train_batches, val_batches, test_batches):\n","       \n","    # Create directory to store TensorBoard checkpoints\n","    writer = misc.createTensorBoardWriter('./results/p05/ResNet9')   \n","          \n","    # Construct the model\n","    model = ResNet9.getModel()\n","    \n","    # Scheduler  \n","    lr_schedule = PiecewiseLinear([0, 3, epochs], [0, 0.4, 0])\n","    lr = lambda step: lr_schedule(step/len(train_batches))/batch_size\n","    \n","    # Define optimizer\n","    optim = SGD(trainable_params(model), lr=lr)\n","    \n","    # Train\n","    train(model, writer, optim, train_batches, val_batches, epochs)\n","\n","    # Evaluate on test set\n","    test(model, writer, test_batches)\n","    \n","    writer.close()"]},{"cell_type":"markdown","metadata":{"id":"QJcb6ZAtDPrf"},"source":["Let's train this network for 10 epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KeSyC83Mr4pi"},"outputs":[],"source":["epochs = 10\n","batch_size = 512\n","\n","# Get dataset\n","train_batches, val_batches, test_batches = ResNet9.getCIFAR10(batch_size)\n","\n","# execute main()\n","main(epochs, batch_size, train_batches, val_batches, test_batches)"]},{"cell_type":"markdown","metadata":{"id":"KNjEEmSfKShN"},"source":["Even though we have trained this ResNet9 model for half of the number of epochs than in the previous notebook, we are achieving ~10% better accuracy. This demonstrates the important of having a good and optimized architecture. "]},{"cell_type":"markdown","metadata":{"id":"8ahBR1mhtwzJ"},"source":["# Other Optimizers"]},{"cell_type":"markdown","metadata":{"id":"Zdp5ro6HEM0R"},"source":["We have always been using the mini-batch SGD optimizer but, as was covered in the slides, multiple different optimizers exists: SGD, SGD-momentum, Adam, Adamax, RMSprop, etc. You can see a side by side comparison in [this blog](https://ruder.io/optimizing-gradient-descent/) of the optimizers covered in the slides and others that have been recently proposed by the research community.\n","\n","In general, when designing a DNN for a new problem, either SGD-momentum or Adam are reasonable choices to start with as they are the two most widely used optimizers.\n","\n","Let's see how the same ResNet9 model as before performs when adding `momentum` and `Nesterov`. You might want to take a look at the documentation for [`torch.optim.SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD)."]},{"cell_type":"markdown","metadata":{"id":"-0c9nkh_Ix13"},"source":["**Complete your code here:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBMkkFueEGck"},"outputs":[],"source":["def main(epochs, batch_size, train_batches, val_batches, test_batches):\n","       \n","    # Create directory to store TensorBoard checkpoints\n","    writer = misc.createTensorBoardWriter('./results/p05/ResNet9')   \n","          \n","    # Construct the model\n","    model = ResNet9.getModel()\n","    \n","    # Scheduler  \n","    lr_schedule = PiecewiseLinear([0, 3, epochs], [0, 0.4, 0])\n","    lr = lambda step: lr_schedule(step/len(train_batches))/batch_size\n","    \n","    # TODO: Define optimizer here\n","    optim = None\n","\n","    # Train\n","    train(model, writer, optim, train_batches, val_batches, epochs)\n","\n","    # Evaluate on test set\n","    test(model, writer, test_batches)\n","    \n","    writer.close()"]},{"cell_type":"markdown","metadata":{"id":"GvGRHS7pN4j6"},"source":["Let's train the model with the new optimizer for 10 epochs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oe-xmGn8E641"},"outputs":[],"source":["epochs = 10\n","batch_size = 512\n","\n","# Get dataset\n","train_batches, val_batches, test_batches = ResNet9.getCIFAR10(batch_size)\n","\n","\n","# print(\"Training for {} epochs using batch size {}\".format(epochs, batch_size))\n","main(epochs, batch_size, train_batches, val_batches, test_batches)"]},{"cell_type":"markdown","metadata":{"id":"vB4iV5PTERd2"},"source":["Observe differences in TensorBoard."]},{"cell_type":"code","source":["%load_ext tensorboard"],"metadata":{"id":"U8kXvoazRucd"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1S6QqIEFQqyz"},"outputs":[],"source":["# Visualize TENSORBOARD\n","\n","%tensorboard --logdir results/p05/"]},{"cell_type":"markdown","metadata":{"id":"64EkZgQr_xg7"},"source":["# What's Next\n","\n","In this notebook we have covered the ResNet architecture, and demonstrated how a good choice of an optimizer can improve the performance of our network.\n","\n","In the following notebooks, we will see how the quality of our dataset also plays a paramount role in solving machine learning tasks."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}